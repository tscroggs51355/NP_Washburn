#!/bin/bash
#SBATCH --job-name=dwnloaddata_Nelms2019       # Job name
#SBATCH --partition=batch              # Partition (queue) name, i.e., highmem_p
#SBATCH --ntasks=1                          # Run a single task
#SBATCH --cpus-per-task=28                  # Number of CPU cores per task
#SBATCH --mem=180gb                          # Job memory request
#SBATCH --time=72:00:00                     # Time limit hrs:min:sec
#SBATCH --output=dwn_nelms.%j.out         # Standard output log
#SBATCH --error=dwn_nelms.%j.err          # Standard error log
#SBATCH --mail-type=END,FAIL                # Mail events (NONE, BEGIN, END, FAIL, ALL)
#SBATCH --mail-user=taylor.strayhorn@uga.edu   # Where to send mail
#SBATCH --export=NONE                       # do not load any env variables to compute node


#Load the three modules associated with this pull - pulls the full bioproject 
module load EDirect/18.7
module load SRA-Toolkit/2.11.1-centos_linux64
module load parallel/20210322-GCCcore-10.2.0

#Gets all the SRR Numbers associated with the bioproject 
esearch -db sra -query PRJNA495390 |\
efetch --format runinfo |\
cut -d "," -f 1 > SRR.numbers

#Download them all in parallel 
parallel --jobs 3 "fastq-dump --split-files --origfmt --gzip {}" ::: SRR.numbers
